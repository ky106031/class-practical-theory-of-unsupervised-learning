{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# AutoEncoderの実装"
      ],
      "metadata": {
        "id": "rZPQ-8P9rbT4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AutoEncoderクラスの定義"
      ],
      "metadata": {
        "id": "ADzFYfvcrjlQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class AE(nn.Module):\n",
        "  def __init__(self, input_dim=10, hidden_dim=5):\n",
        "    super(AE, self).__init__()\n",
        "    self.input_dim = input_dim\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.output_dim = input_dim\n",
        "\n",
        "    self.encoder = nn.Linear(input_dim, hidden_dim)\n",
        "    self.decoder = nn.Linear(hidden_dim, self.output_dim)\n",
        "\n",
        "  def encode(self, data):\n",
        "    return torch.sigmoid(self.encoder(data))\n",
        "\n",
        "  def decode(self, data):\n",
        "    return torch.sigmoid(self.decoder(data))\n",
        "\n",
        "  def forward(self, data):\n",
        "    encoded = self.encode(data)\n",
        "    decoded = self.decode(encoded)\n",
        "\n",
        "    return decoded\n",
        "\n"
      ],
      "metadata": {
        "id": "rZByhmPQeeji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## dataの取得"
      ],
      "metadata": {
        "id": "9-iX7k_2rpdW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "sklearn の数字データとする"
      ],
      "metadata": {
        "id": "xamvU2RWrtwe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_digits\n",
        "from sklearn import svm\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "digits = load_digits()\n",
        "x = digits.data / 16.\n",
        "y = digits.target\n",
        "images = digits.images /16.\n",
        "\n",
        "x_train, x_test, y_train, y_test, images_train, images_test = train_test_split(x, y, images, train_size=0.7)\n",
        "\n",
        "\n",
        "print(len(x[0,:]))\n",
        "print(images[1])\n",
        "\n",
        "n_features = len(x[0,:])\n",
        "hidden_dim = n_features // 2"
      ],
      "metadata": {
        "id": "2FGDdycCkcIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(images[1], cmap=plt.cm.gray_r)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "w7wd9PyykrTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DataSetの作成"
      ],
      "metadata": {
        "id": "oXlPel7urzmm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "  def __init__(self, datas, labels):\n",
        "    super().__init__()\n",
        "\n",
        "    self.len = len(labels)\n",
        "    self.datas = datas\n",
        "    self.labels = labels\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.len\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    data = self.datas[index]\n",
        "    label = self.labels[index]\n",
        "    data = data.astype(np.float32)\n",
        "    data = torch.from_numpy(data)\n",
        "    return data, label\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oyMoCsTAhlfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DataLoaderの作成"
      ],
      "metadata": {
        "id": "lrA9ZT-wr79N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "dataset = MyDataset(x_train, y_train)\n",
        "dataloader =  DataLoader(dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "spDKebYfiWW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 学習用の関数"
      ],
      "metadata": {
        "id": "Hf4JTD7fr_09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, criterion, num_epoch):\n",
        "  model.train()\n",
        "  for epoch in range(num_epoch):\n",
        "    for iter, (data, labels) in enumerate(dataloader,1):\n",
        "      optimizer.zero_grad()\n",
        "      pred = model(data)\n",
        "      loss = criterion(pred, data)\n",
        "      loss.backward() #誤差伝播\n",
        "      optimizer.step() #パラメータ更新\n",
        "      if (iter % 10 == 0 ):\n",
        "        print(\"epoch[%d/%d] iter=%d: loss=%f\" % (epoch+1, num_epoch, iter, loss.item()))\n",
        "        #print(\"loss =\", torch.sum((pred-data)**2)/len(pred[0]))\n",
        "\n"
      ],
      "metadata": {
        "id": "DIf34OkqhaKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## モデルのインスタンス化と学習"
      ],
      "metadata": {
        "id": "nlzmKpJTsMUV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ae1 = AE(input_dim=n_features, hidden_dim=hidden_dim)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.RMSprop(ae1.parameters())\n",
        "\n",
        "train(ae1, criterion, 10)"
      ],
      "metadata": {
        "id": "5zt6BmBti8o5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 再構成テスト"
      ],
      "metadata": {
        "id": "NCmn-vtIsSw9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ae1.eval()\n",
        "data = dataset[0][0]\n",
        "\n",
        "pred = ae1.decode(ae1.encode(data))\n",
        "pred = pred.detach().numpy()\n",
        "\n",
        "plt.imshow(pred.reshape([8,8]), cmap=plt.cm.gray_r)\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(data.reshape([8,8]), cmap=plt.cm.gray_r)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "n_9Pl0CgsUEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 取り出した中間ベクトルの評価"
      ],
      "metadata": {
        "id": "n1ocks_9stfM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 圧縮前のベクトルでどれくらい識別できるか（10種類の数字の10クラス分類）"
      ],
      "metadata": {
        "id": "lQnDw4g4sxGk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn import linear_model\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "\n",
        "clf = linear_model.Perceptron()\n",
        "clf.fit(x_train, y_train)\n",
        "\n",
        "pred = clf.predict(x_test)\n",
        "print(classification_report(y_test, pred))\n",
        "print(accuracy_score(y_test, pred))\n",
        "print(confusion_matrix(y_test, pred))\n"
      ],
      "metadata": {
        "id": "SXO-uITTyhWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 中間ベクトルでの識別結果"
      ],
      "metadata": {
        "id": "MEFbaisQs8BE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn import linear_model\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "\n",
        "ae1.eval()\n",
        "clf = linear_model.Perceptron()\n",
        "encoded = ae1.encode(torch.from_numpy(x_train.astype(np.float32)))\n",
        "clf.fit(encoded.detach().numpy(), y_train)\n",
        "\n",
        "encoded = ae1.encode(torch.from_numpy(x_test.astype(np.float32)))\n",
        "pred = clf.predict(encoded.detach().numpy())\n",
        "print(classification_report(y_test, pred))\n",
        "print(accuracy_score(y_test, pred))\n",
        "print(confusion_matrix(y_test, pred))"
      ],
      "metadata": {
        "id": "4WA6BMIxzCYX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}